# 第19章 大数据架构设计理论与实践

- **19.1 传统数据处理系统存在的问题**
    - **性能瓶颈**: 随着数据量增加，数据库无法支撑负载
    - **扩展困难**: 
        - **读写分离/分库分表**: 增加应用逻辑复杂度 (了解Schema, 路由)
        - **水平分区 (Sharding)**: Resharding 耗时痛苦, 需要迁移数据, 更新代码
    - **容错性差**: 难以应对人为错误, 仅靠备份无法治本
- **19.2 大数据处理系统架构分析**
    - **面临挑战**:
        - **数据类型**: 非结构化/半结构化数据 (85%), 高维, 多变, 强随机性
        - **复杂性**: 数据挖掘 "一次挖掘" (粗糙知识) vs "二次挖掘" (智能知识)
        - **异构性**: 数据异构性 vs 决策异构性
    - **架构特征**:
        - **鲁棒性与容错性**: 应对机器故障和人为错误
        - **低延迟**: 毫秒级读取和更新
        - **横向扩容 (Scale Out)**: 线性扩展
        - **通用性**: 支持多种应用场景
        - **延展性**: 易于添加新功能
        - **即席查询 (Ad Hoc Queries)**: 灵活查询能力
        - **最少维护**: 降低复杂度
        - **可调试性**: 数据可追踪
- **19.3 Lambda 架构**
    - **核心理念**: 整合离线计算与实时计算, 融合不可变性, 读写分离, 复杂性隔离
    - **三层结构**:
        - **批处理层 (Batch Layer)**:
            - **功能**: 存储主数据集 (不可变, 永远真实), 生成 Batch View
            - **特性**: 满足 Monoid 性质 (结合律), 预计算, 高延迟, 高吞吐
        - **加速层 (Speed Layer)**:
            - **功能**: 处理最近的增量数据流, 生成 Real-time View
            - **特性**: 低延迟, 结果近似 (最终一致性), 复杂性较高
        - **服务层 (Serving Layer)**:
            - **功能**: 合并 Batch View 和 Real-time View, 响应查询
            - **特性**: 随机读取, 批量写入
    - **技术实现 (典型)**:
        - **存储**: Hadoop (HDFS)
        - **批处理**: MapReduce / Spark
        - **流处理**: Storm / Spark Streaming
        - **服务/视图**: HBase / Cassandra / Hive / Impala
    - **优缺点**:
        - **优点**: 容错性好, 查询灵活, 易伸缩/扩展
        - **缺点**: 编码开销大 (两套代码), 运维成本高, 数据迁移成本高
- **19.4 Kappa 架构**
    - **核心理念**: 简化 Lambda, 移除 Batch Layer, 一切皆是流 (Stream)
    - **数据特性**:
        - **When**: 时间相关性
        - **What**: 数据不可变 (Immutable), 操作仅为 CR (Create, Read)
    - **架构原理**:
        - **单一路径**: 通过流计算处理所有数据 (实时 + 历史回溯)
        - **数据重放**: 修改逻辑时, 重放历史消息队列
    - **实现 (典型)**:
        - **消息队列**: Kafka (保留期设置长或永久)
        - **流计算**: Flink / Samza
        - **存储/查询**: ElasticSearch / HBase
    - **优缺点**:
        - **优点**: 维护一套代码, 开发维护成本低, 统一数据口径
        - **缺点**: 消息中间件回溯瓶颈, 历史数据处理能力弱于批处理
    - **常见变形**:
        - **Kappa+**: 结合 HDFS/S3 存储历史数据 (如 Uber 方案), 使用 Hudi/Delta Lake
        - **混合分析**: 结合 ElasticSearch 增强短时热点查询
- **19.5 架构对比与选择**
    - **对比维度**:
        - **复杂度**: Lambda 高 (两套系统) vs Kappa 低 (一套系统)
        - **计算开销**: Lambda 大 (持续运行) vs Kappa 小 (按需全量)
        - **实时性**: 均满足
        - **历史数据能力**: Lambda 强 (批处理优势) vs Kappa 弱 (依赖消息队列性能)
    - **选择策略**:
        - **业务需求**: 强依赖 Hadoop 选 Lambda; 偏好流式选 Kappa
        - **算法需求**: 参数频繁修改/单一代码逻辑 选 Kappa; 必须离线训练+在线预测 选 Lambda
        - **历史数据**: 频繁大规模历史分析 选 Lambda; 主要是小规模/实时窗口 选 Kappa
- **19.6 案例分析**
    - **某网奥运视频平台 (Lambda)**:
        - **需求**: 秒级实时概览 + 海量历史回顾
        - **架构**: 
            - **离线**: Spark/MR -> Hive -> HDFS -> Batch View
            - **实时**: Flume -> Kafka -> Spark Streaming -> Real-time View
            - **合并**: MemSQL + HBase
    - **某网广告平台 (Lambda 演进)**:
        - **演进**: 
            - v1 (典型Lambda, Java端合并复杂) -> 
            - v2 (Hive预聚合, 减轻Java端) -> 
            - v3 (MySQL单表, 实时更新st_day, 极简服务层)
    - **某证券日志分析 (Kappa)**:
        - **需求**: 统一日志管理, 智能搜索, 实时监控
        - **架构**: Filebeat -> Kafka -> Flink (清洗/指标) -> ElasticSearch (日志) + OpenTSDB (指标)
    - **某电商智能决策 (Kappa)**:
        - **需求**: 实时竞价/推荐, 模型快速迭代
        - **架构**: 业务流 -> Kafka -> Flink -> Tair (参数) / Hive (日志) -> 决策服务 (Client拉取本地缓存)
